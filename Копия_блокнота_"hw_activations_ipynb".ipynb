{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HitLing/-match-3/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22hw_activations_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQl6BxbTv-eK"
      },
      "source": [
        "# Activations\n",
        "\n",
        "В этой тетрадке мы напишем собственную реализацию функций активации\n",
        "\n",
        "\n",
        "Запрещено внутри своей реализации создавать класс активации из pytorch и просто применять его. Разрешено исползовать простые ф-ии pytorch типа [torch.exp](https://pytorch.org/docs/stable/generated/torch.exp.html) и т д\n",
        "\n",
        "Если у ф-ии активации есть дополнительные аргументы, значение по умолчанию должно быть такое же как в реализации PyTorch\n",
        "\n",
        "**Материалы по pytorch:**\n",
        "\n",
        "* [PyTorch docs](https://pytorch.org/docs/stable/index.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNMlqoCiv-eM"
      },
      "source": [
        "## Prerequirements\n",
        "\n",
        "```\n",
        "pip install torch numpy\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-24T12:02:03.697132Z",
          "iopub.status.busy": "2021-01-24T12:02:03.696647Z",
          "iopub.status.idle": "2021-01-24T12:02:05.150001Z",
          "shell.execute_reply": "2021-01-24T12:02:05.148949Z",
          "shell.execute_reply.started": "2021-01-24T12:02:03.697089Z"
        },
        "id": "ovtEtMOxv-eN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGTRWWFo5pOy"
      },
      "source": [
        "## Задание 1\n",
        "**(0.25 балла)** Напишите свою версию версию функции активации [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9rZXbfck6WPO"
      },
      "outputs": [],
      "source": [
        "# Из ячейки не нужно убирать или добавлять другие импорты или объединять с тдругими ячейками\n",
        "# Это может сломать автотесты\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyReLU(nn.Module):\n",
        "\n",
        "    def forward(self, input):\n",
        "        # hint! Входной тензор нужно скопировать,\n",
        "        # чтобы действиями внутри этого метода не привели к изменению внешнего аргумента\n",
        "        input_clone = torch.clone(input)\n",
        "        if(input_clone <=0):\n",
        "          return 0\n",
        "        else:\n",
        "          return input_clone\n",
        "        # return ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRV-Ea2N5zDb"
      },
      "source": [
        "## Задание 2\n",
        "**(0.25 балла)** Напишите свою версию версию функции активации [LeakyReLU](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1ouIrrlq63uN"
      },
      "outputs": [],
      "source": [
        "# Из ячейки не нужно убирать или добавлять другие импорты или объединять с тдругими ячейками\n",
        "# Это может сломать автотесты\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyLeakyReLU(nn.Module):\n",
        "\n",
        "    def forward(self, input):\n",
        "        # hint! Входной тензор нужно скопировать,\n",
        "        # чтобы действиями внутри этого метода не привели к изменению внешнего аргумента\n",
        "        input_clone = torch.clone(input)\n",
        "        if(input_clone <=0):\n",
        "          return 0.1 * input_clone\n",
        "        else:\n",
        "          return input_clone\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS2RXTz_55iS"
      },
      "source": [
        "## Задание 3\n",
        "**(0.25 балла)** Напишите свою версию версию функции активации [Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QTHnuZQA67ga"
      },
      "outputs": [],
      "source": [
        "# Из ячейки не нужно убирать или добавлять другие импорты или объединять с тдругими ячейками\n",
        "# Это может сломать автотесты\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MySigmoid(nn.Module):\n",
        "\n",
        "    def forward(self, input):\n",
        "        return (1/(1+math.exp(input)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGZs035Rv-eS"
      },
      "source": [
        "## Задание 4\n",
        "**(0.25 балла)** Напишите свою версию версию функции активации [ELU](https://pytorch.org/docs/stable/generated/torch.nn.ELU.html#torch.nn.ELU)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CT1IEmzFv-eT"
      },
      "outputs": [],
      "source": [
        "# Из ячейки не нужно убирать или добавлять другие импорты или объединять с тдругими ячейками\n",
        "# Это может сломать автотесты\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyELU(nn.Module):\n",
        "\n",
        "    def forward(self, input):\n",
        "        input_clone = torch.clone(input)\n",
        "        if(input_clone>0):\n",
        "          return input_clone\n",
        "        else:\n",
        "          return (math.exp(input_clone) - 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUfu8arDKoNm"
      },
      "source": [
        "## Тест\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uAagGpwSKqBN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "282ee2ed-52d6-4f5e-f69c-c212ddc6289c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'myrelu.py'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4eca91709657>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mtest_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mtest_leaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mtest_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4eca91709657>\u001b[0m in \u001b[0;36mtest_relu\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmy_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0m_check_pytorch_module_was_not_used\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"myrelu.py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.ReLU('\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0m_test_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_activation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4eca91709657>\u001b[0m in \u001b[0;36m_check_pytorch_module_was_not_used\u001b[0;34m(file, module)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_pytorch_module_was_not_used\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pytorch module must not be used in you activation implementation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'myrelu.py'"
          ]
        }
      ],
      "source": [
        "import pytest\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def _check_pytorch_module_was_not_used(file, module):\n",
        "\n",
        "    file = open(file, mode='r')\n",
        "\n",
        "    assert module not in file.read(), \"pytorch module must not be used in you activation implementation\"\n",
        "\n",
        "    file.close()\n",
        "\n",
        "    return\n",
        "\n",
        "def _test_activation(myactivation, torch_activation):\n",
        "    print(myactivation)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        randinput = torch.rand([100])\n",
        "        myactivation_output = myactivation(randinput)\n",
        "\n",
        "        assert id(myactivation_output) != id(randinput), 'pytorch activation function must return new tensor'\n",
        "\n",
        "        for _ in range(100):\n",
        "            randinput = torch.rand([5, 5, 5])\n",
        "\n",
        "            assert torch.allclose(myactivation(randinput), torch_activation(randinput)), 'activation output is not equals to touch ones output'\n",
        "\n",
        "def test_relu():\n",
        "\n",
        "    my_activation = MyReLU()\n",
        "\n",
        "    _check_pytorch_module_was_not_used(\"myrelu.py\", '.ReLU(')\n",
        "    _test_activation(my_activation, nn.ReLU())\n",
        "\n",
        "def test_leaky_relu():\n",
        "\n",
        "    my_activation = MyLeakyReLU()\n",
        "\n",
        "    _check_pytorch_module_was_not_used(\"myleakyrelu.py\", '.LeakyReLU(')\n",
        "    _test_activation(my_activation, nn.LeakyReLU())\n",
        "\n",
        "def test_sigmoid():\n",
        "\n",
        "    my_activation = MySigmoid()\n",
        "\n",
        "    _check_pytorch_module_was_not_used(\"mysigmoid.py\", '.MySigmoid(')\n",
        "    _test_activation(my_activation, nn.Sigmoid())\n",
        "\n",
        "def test_elu():\n",
        "\n",
        "    my_activation = MyELU()\n",
        "\n",
        "    _check_pytorch_module_was_not_used(\"myelu.py\", '.MyELU(')\n",
        "    _test_activation(my_activation, nn.ELU())\n",
        "\n",
        "\n",
        "test_relu()\n",
        "test_leaky_relu()\n",
        "test_sigmoid()\n",
        "test_elu()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GyfzQENzy1k2"
      },
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "toc-autonumbering": false
  },
  "nbformat": 4,
  "nbformat_minor": 0
}